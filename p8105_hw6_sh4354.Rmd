---
title: "Homework 6"
author: "Selina Hsuan"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

```{r}
library(tidyverse)
library(modelr)
library(mgcv)

set.seed(1)
```


## Problem 1

Import and clean dataset 
```{r}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) |> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) |> 
  filter(victim_race %in% c("White", "Black")) |> 
  filter(!(city_state %in% c("Tulsa, AL", "Dallas, TX", "Phoenix, AZ", "Kansas City, MO"))) |> 
  select(city_state, resolution, victim_age, victim_sex, victim_race)
```


For Balimore, MD, fit logistic regression model and obtain estimate and CI of odds ratio comparing male to female victims
```{r}
baltimore_glm = 
  filter(homicide_df, city_state == "Baltimore, MD") |> 
  glm(resolution ~ victim_age + victim_sex + victim_race, family = binomial(), data = _)

baltimore_glm |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(OR, OR_CI_lower, OR_CI_upper) |>
  knitr::kable(digits = 3)
```

Conduct same analysis for each city
```{r}
model_results = 
  homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(data, \(df) glm(resolution ~ victim_age + victim_sex + victim_race, 
                             family = binomial(), data = df)),
    tidy_models = map(models, broom::tidy)) |> 
  select(-models, -data) |> 
  unnest(cols = tidy_models) |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, OR, OR_CI_lower, OR_CI_upper)

model_results |>
  slice(1:5) |> 
  knitr::kable(digits = 3)
```

Generate plot
```{r}
model_results |> 
  mutate(city_state = fct_reorder(city_state, OR)) |> 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = OR_CI_lower, ymax = OR_CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```



## Problem 2

Download data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```


create simple linear regression model
```{r}
model = 
  weather_df |> 
  lm(tmax ~ tmin + prcp, data = _) |> 
  broom::glance() |> 
  select(r.squared)
```


```{r}
weather_df |> 
  lm(tmax ~ tmin + prcp, data = _) |> 
  broom::tidy() |> 
  slice(c(2,3)) |> 
  select(term, estimate) |> 
  pivot_wider(
    names_from = term, values_from = estimate
    ) |> 
  mutate(log = ifelse(tmin > 0 & prcp > 0, log(tmin * prcp), NA))
```

create bootstrap function
```{r}
boot_sample = function(df) {
  
  data = sample_frac(df, replace = TRUE)
  
  output1 = data |> 
    lm(tmax ~ tmin + prcp, data = _) |> 
    broom::glance() |> 
    select(r.squared)
  
  output2 = data |> 
  lm(tmax ~ tmin + prcp, data = _) |> 
  broom::tidy() |> 
  slice(c(2,3)) |> 
  select(term, estimate) |> 
  pivot_wider(
    names_from = term, values_from = estimate
    ) |> 
  mutate(log = ifelse(tmin > 0 & prcp > 0, log(tmin * prcp), NA)) |> 
  select(log)
  
  tibble(
    output1,
    output2
  )
}
```

draw many samples 
```{r}
boot_straps = 
  tibble(strap_number = 1:5000) |> 
  mutate(
    strap_sample = map(strap_number, \(i) boot_sample(weather_df))
  ) |> 
  unnest(strap_sample)

```

plot distribution of R square values
```{r}
boot_straps |> 
  ggplot(aes(x = r.squared)) + 
  geom_density()
```

plot distribution of log values
```{r}
boot_straps |> 
  ggplot(aes(x = log)) + 
  geom_density()
```

Out of 5000 values of log(β1*β2), 3331 were removed from the analysis because the value was "N/A". 



calculate 95% confidence intervals
```{r}
boot_straps |> 
  select(r.squared,log) |> 
  pivot_longer(
    cols = c(r.squared, log),
    names_to = "quantity", 
    values_to = "estimate"
  ) |> 
  group_by(quantity) |> 
  summarize(
    ci_lower = quantile(estimate, 0.025, na.rm = TRUE),
    ci_upper = quantile(estimate, 0.975, na.rm = TRUE))
 
```

## Problem 3

Load data
```{r}
birthweight =
  read_csv("data/birthweight.csv") |> 
  janitor::clean_names() |> 
  mutate(babysex = as.factor(babysex))
```

create regression model
```{r}
model = 
  birthweight |> 
  lm(bwt ~ blength + fincome, data = _)
```
I hypothesize that baby's length at birth (blength) and family monthly income (fincome) may be a good model for birth weight. The baby's length is likely directly related due birth weight because a larger baby weighs more. Family income may also be related to birth weight due to social determinants of health, in which families with lower income have babies with lower weight. 


plot model residuals against predicted values
```{r}
birthweight |> 
  modelr::add_predictions(model) |> 
  modelr::add_residuals(model) |> 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  labs(title = "Residuals vs. Fitted Values",
       x = "Fitted Values",
       y = "Residuals") 
```


model comparisons
```{r}
comparison1 = 
  birthweight |> 
  lm(bwt ~ blength + gaweeks, data = _)

comparison2 = 
  birthweight |> 
  lm(bwt ~ babysex*bhead*blength, data = _)
```

```{r}
birthweight |> 
  gather_predictions(model, comparison1, comparison2) |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = blength, y = bwt)) + 
  geom_point(alpha = .5) +
  geom_line(aes(y = pred), color = "red") + 
  facet_grid(~model)
```

```{r}
cv_df =
  crossv_mc(birthweight, 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

```{r}
cv_df = 
  cv_df |> 
  mutate(
    model_mod  = map(train, \(df) lm(bwt ~ blength + fincome, data = df)),
    comparison1_mod     = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    comparison2_mod  = map(train, \(df) lm(bwt ~ babysex*bhead*blength, data = df))) |> 
  mutate(
    rmse_model = map2_dbl(model_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_comparison1    = map2_dbl(comparison1_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_comparison2 = map2_dbl(comparison2_mod, test, \(mod, df) rmse(model = mod, data = df)))
```


```{r}
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

Between the 3 regression models, the second comparison model with interactions has the lowest RSME distribution and the best predictive accuracy. 
